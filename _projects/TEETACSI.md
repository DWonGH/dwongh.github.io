---
title: "TEETACSI"
excerpt: "Tracking Expert Eyes to Train AI for Clinical Signal Interpretation<br/><img src='images/eyetracker.gif'>"
collection: projects
---

Managing our society’s growing burden of neurological disorders will require significant advances in our ability to efficiently assess a patient’s neurological state. Electroencephalography (EEG) is already, and will increasingly be, an important tool in this effort; it is the only clinically convenient measurement technique with adequate time-resolution to capture human thought processes. However, its use in current practice is severely restricted by the availability of trained neurophysiologists to interpret the recordings. 

Numerous studies have attempted automated interpretation of EEG by techniques such as deep learning [Craik et al, 2019]. Such approaches tend to be heavily dependent on time-consuming manual pre-processing and annotation, or restricted to applications/conditions in which these are not required. In realistic clinical conditions, the state-of-the-art technique exhibits an accuracy of 90% in detecting features of interest [Golmohammadi et al, 2019], insufficient for confident clinical use, particularly as the ability to accurately classify these features is even lower.

The aim of this project is to improve on this performance by replicating human expertise in identifying which sections of a signal to focus on.

Research question: ‘Can the training of deep neural networks for automated clinical EEG analysis be improved with eye-tracking of experienced human interpreters?’

![GIF showing TEETACSI's tracking of eye gaze relative to on-screen EEG signals.](https://raw.githubusercontent.com/DWonGH/dwongh.github.io/master/images/eyetracker.gif)

<image src="https://raw.githubusercontent.com/DWonGH/dwongh.github.io/master/images/eyetracker.gif" alt="GIF showing TEETACSI's tracking of eye gaze relative to on-screen EEG signals." width="450" /> 
